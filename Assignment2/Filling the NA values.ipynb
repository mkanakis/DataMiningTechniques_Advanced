{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPUTING VALUES FOR THE NAN'S\n",
    "\n",
    "\n",
    "# visitor_hist_starrating:  94.92 %\n",
    "After some testing it doesnt seem to matter if we impute the mean/median of all entries, or we train a model to predict the starrating, or we impute the mean of the people from the same country with the same destination. All the MSE's were the same.\n",
    "\n",
    "\n",
    "# visitor_hist_adr_usd:  94.9 %\n",
    "After some testing it doesnt seem to matter if we impute the mean/median of all entries, or we train a model to predict the history usd, or we impute the mean of the people from the same country with the same destination. All the MSE's were the same.\n",
    "\n",
    "\n",
    "# prop_review_score:  0.15 %\n",
    "If a hotel doesnt have a review score, the same hotel also doesnt have a review score in other searches. The correlation between prop_review_score and click_bool is highest when we impute 0 for the missing values.\n",
    "\n",
    "\n",
    "# prop_location_score2:  21.99 %\n",
    "It seems that the location_score2 is based on the search destination and the hotel location. It is probable that the further away the hotel is from the original search destination the lower the location_score2 is. Furthermore, after inspection of this attribute it seems that there exists a modest negative correlation between position and location_score2 (with filtering a filter on the random results) [r = -.20]. The hotels with missing values for location_score2 are ranked almost always at the bottom (position mean = 19, sd = 6). So i suggest we impute 0 for missing values of this attribute. This would also increase the significance between the location_score2 and the click_bool (i.e. the probability of a click is twice as unlikely when it doesnt have a location_score2)\n",
    "\n",
    "\n",
    "# srch_query_affinity_score:  93.6 %\n",
    "Some hotels with a nan value have an affinity score in another search. If we use the mean of the affinity scores from other searches it is significantly more accurate than the mean of all searches. When a hotel doesnt have an affinity score anywhere, the mean of the affinity scores in the same search destination is used. The RMSE of this procedure is 13.88 (SD = 31.36) while the RMSE of using the mean of everything is 16.07 (SD = 34.30).\n",
    "\n",
    "\n",
    "# orig_destination_distance:  32.43 %\n",
    "Either a search has the distance for every result or for none. Imputing the mean leads to a RMSE of 2000km (sd = 3300km), but imputing the mean of the people from the same country going to the same destination leads to a RMSE of 560km (sd = 800km)*. So i think that this would be a great solution to fill in the NA values for orig_destination_distance!\n",
    "\n",
    "*if there were no people from the same country A going to the same destination in country B, i used the mean of the people from country A that go to country B (so less specific than the same destination within country B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4958347, 54)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('training_set_VU_DM_2014.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\tPercentage of missing values:')\n",
    "for column in df.columns:\n",
    "    percentage = round((len(df[df[column].isnull()])/len(df))*100,2)\n",
    "    if percentage > 0:\n",
    "        print(column + ': ', percentage, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mick\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visitor_hist_starrating had an original correlation of 0.00254 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "visitor_hist_adr_usd had an original correlation of 0.00386 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "prop_review_score had an original correlation of r = 0.02342 with the click_bool. \n",
      "Best option: impute zero with r = 0.02344\n",
      "\n",
      "prop_location_score2 had an original correlation of r = 0.07381 with the click_bool. \n",
      "Best option: impute zero with r = 0.08309\n",
      "\n",
      "srch_query_affinity_score had an original correlation of 0.04176 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "orig_destination_distance had an original correlation of 0.00229 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First check the simplest solutions of imputing 1 value for all missing values in a column\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "for column in ['visitor_hist_starrating','visitor_hist_adr_usd', 'prop_review_score',\n",
    "'prop_location_score2','srch_query_affinity_score','orig_destination_distance']:\n",
    "    \n",
    "    result = []\n",
    "    df2 = df[[column, 'click_bool']]\n",
    "\n",
    "    r1, p = pearsonr(df2[df2[column].notnull()][column], df2[df2[column].notnull()]['click_bool'])\n",
    "    result.append((r1, 'old'))\n",
    "    for option in ['mean', 'median', 'zero', 'firstq', 'thirdq']:\n",
    "        df2 = df[[column, 'click_bool']]\n",
    "        if option == 'mean':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].mean())\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'median':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].median())\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'zero':\n",
    "            df2.loc[:,column] = df2[column].fillna(0)\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'firstq':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].quantile(q = .25))\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'thirdq':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].quantile(q = .75))\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        result.append((r, option))\n",
    "    best_corr, best_option = max(result)\n",
    "    if best_option != 'old':\n",
    "        print(f\"{column} had an original correlation of r = {round(r1, 5)} with the click_bool. \\nBest option: impute {best_option} with r = {round(best_corr, 5)}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{column} had an original correlation of {round(r1, 5)} with the click_bool. \\nThere was no better alternative.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visitor_hist_starrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "dfstar = df[df['visitor_hist_starrating'].notnull()][['srch_id', 'visitor_location_country_id', 'srch_destination_id', 'prop_country_id', 'visitor_hist_starrating']].drop_duplicates()\n",
    "pred = list()\n",
    "h = 0\n",
    "for entry in dfstar.values:\n",
    "    visitor_country_id = entry[1]\n",
    "    srch_id = entry[0]\n",
    "    srch_dest = entry[2]\n",
    "    country = entry[3]\n",
    "    same_loc_df = dfstar[(dfstar['visitor_location_country_id'] == visitor_country_id) & (dfstar['srch_id'] != srch_id) &(dfstar['srch_destination_id'] == srch_dest)]\n",
    "    if len(same_loc_df) > 0:\n",
    "        pred.append(same_loc_df['visitor_hist_starrating'].mean())\n",
    "    else: # if there are no other searches from the same country with a history\n",
    "        same_loc_df = dfstar[(dfstar['visitor_location_country_id'] == visitor_country_id) & (dfstar['srch_id'] != srch_id) &(dfstar['prop_country_id'] == country)]\n",
    "        if len(same_loc_df) > 0:\n",
    "            pred.append(same_loc_df['visitor_hist_starrating'].mean())\n",
    "        else: # if there are no other searches from the same countro to the same country with a history\n",
    "            h+=1\n",
    "            pred.append(dfstar[dfstar['srch_id'] != srch_id]['visitor_hist_starrating'].mean())\n",
    "pred = np.asarray(pred)\n",
    "\n",
    "print('\\tImpute mean of the people from the same country:')\n",
    "print('MSE:', math.sqrt(((dfstar['visitor_hist_starrating'] - pred)**2).mean()))\n",
    "print('SD:', math.sqrt(((dfstar['visitor_hist_starrating'] - pred)**2).std()))\n",
    "print()\n",
    "print('\\tImpute mean of everyone:')\n",
    "print('MSE:', math.sqrt(((dfstar['visitor_hist_starrating'] - dfstar['visitor_hist_starrating'].mean())**2).mean()))\n",
    "print('SD:', math.sqrt(((dfstar['visitor_hist_starrating'] - dfstar['visitor_hist_starrating'].mean())**2).std()))\n",
    "print()\n",
    "print(f'{round(h/len(dfstar),2)*100} % of the instances had no other searches from the same country with a history.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visitor_hist_adr_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "dfstar = df[df['visitor_hist_adr_usd'].notnull()][['srch_id', 'visitor_location_country_id', 'srch_destination_id', 'prop_country_id', 'visitor_hist_adr_usd']].drop_duplicates()\n",
    "pred = list()\n",
    "i = 0\n",
    "for entry in dfstar.values:\n",
    "    visitor_country_id = entry[1]\n",
    "    srch_id = entry[0]\n",
    "    srch_dest = entry[2]\n",
    "    country = entry[3]\n",
    "    same_loc_df = dfstar[(dfstar['visitor_location_country_id'] == visitor_country_id) & (dfstar['srch_id'] != srch_id) &(dfstar['srch_destination_id'] == srch_dest)]\n",
    "    if len(same_loc_df) > 0:\n",
    "        pred.append(same_loc_df['visitor_hist_adr_usd'].mean())\n",
    "    else: # if there are no other searches from the same country to the same destination with a history\n",
    "        same_loc_df = dfstar[(dfstar['visitor_location_country_id'] == visitor_country_id) & (dfstar['srch_id'] != srch_id) &(dfstar['prop_country_id'] == country)]\n",
    "        if len(same_loc_df) > 0:\n",
    "            pred.append(same_loc_df['visitor_hist_adr_usd'].mean())\n",
    "        else: # if there are no other searches from the same countro to the same country with a history\n",
    "            i += 1\n",
    "            pred.append(dfstar[dfstar['srch_id'] != srch_id]['visitor_hist_adr_usd'].mean())\n",
    "\n",
    "pred = np.asarray(pred)\n",
    "\n",
    "print('\\tImpute mean of the people from the same country:')\n",
    "print('MSE:', math.sqrt(((dfstar['visitor_hist_adr_usd'] - pred)**2).mean()))\n",
    "print('SD:', math.sqrt(((dfstar['visitor_hist_adr_usd'] - pred)**2).std()))\n",
    "print()\n",
    "print('\\tImpute mean of everyone:')\n",
    "print('MSE:', math.sqrt(((dfstar['visitor_hist_adr_usd'] - dfstar['visitor_hist_adr_usd'].mean())**2).mean()))\n",
    "print('SD:', math.sqrt(((dfstar['visitor_hist_adr_usd'] - dfstar['visitor_hist_adr_usd'].mean())**2).std()))\n",
    "print()\n",
    "print(f'{round(i/len(dfstar),2)*100} % of the instances had no other searches from the same country with a history.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Origin destination distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "dfstar = df[df['orig_destination_distance'].notnull()][['srch_id', 'visitor_location_country_id', 'srch_destination_id', 'prop_country_id', 'orig_destination_distance']].drop_duplicates()\n",
    "pred = list()\n",
    "h = 0\n",
    "for entry in dfstar.values[::4000]:\n",
    "    visitor_country_id = entry[1]\n",
    "    srch_id = entry[0]\n",
    "    srch_dest = entry[2]\n",
    "    country = entry[3]\n",
    "    same_loc_df = dfstar[(dfstar['visitor_location_country_id'] == visitor_country_id) & (dfstar['srch_destination_id'] == srch_dest)]\n",
    "    if len(same_loc_df) > 0:\n",
    "        pred.append(same_loc_df['orig_destination_distance'].mean())\n",
    "    else: # if there are no other searches from the same country with a history\n",
    "        same_loc_df = dfstar[(dfstar['visitor_location_country_id'] == visitor_country_id) & ( dfstar['prop_country_id'] == country)]\n",
    "        if len(same_loc_df) > 0:\n",
    "            pred.append(same_loc_df['orig_destination_distance'].mean())\n",
    "        else: # if there are no other searches from the same country to the same country with a history\n",
    "            h+=1\n",
    "            pred.append(dfstar[dfstar['srch_id'] != srch_id]['orig_destination_distance'].mean())\n",
    "pred = np.asarray(pred)\n",
    "\n",
    "print('\\tImpute mean of the people from the same country:')\n",
    "print('MSE:', math.sqrt(((dfstar['orig_destination_distance'][::4000] - pred)**2).mean()))\n",
    "print('SD:', math.sqrt(((dfstar['orig_destination_distance'][::4000] - pred)**2).std()))\n",
    "print()\n",
    "print('\\tImpute mean of everyone:')\n",
    "print('MSE:', math.sqrt(((dfstar['orig_destination_distance'][::4000] - dfstar['orig_destination_distance'][::4000].mean())**2).mean()))\n",
    "print('SD:', math.sqrt(((dfstar['orig_destination_distance'][::4000] - dfstar['orig_destination_distance'][::4000].mean())**2).std()))\n",
    "print()\n",
    "print(f'{round(h/len(dfstar),2)*100} % of the instances had no other searches from the same country with a history.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# srch_query_affinity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# since there are a lot of hotels with nan values that dont have none values for some other searches it is faster\n",
    "# to create a database with the mean affinity score for every hotel, with search destination\n",
    "# WARNING: this may take a while to complete\n",
    "\n",
    "df2 = df[['prop_id', 'srch_destination_id', 'srch_query_affinity_score']]\n",
    "\n",
    "props = []\n",
    "means = []\n",
    "srch_destination = []\n",
    "prop_id_set = set(df2[df2['srch_query_affinity_score'].notnull()]['prop_id'])\n",
    "deci = int(len(prop_id_set)/10)\n",
    "i = 0\n",
    "\n",
    "for prop in prop_id_set:\n",
    "    propdf = df2[(df2['prop_id'] == prop)]\n",
    "    prop2df = propdf[propdf['srch_query_affinity_score'].notnull()]\n",
    "    if len(prop2df) > 0:\n",
    "        mean = prop2df['srch_query_affinity_score'].mean()\n",
    "        srch_dest = propdf['srch_destination_id'].mode()\n",
    "        if len(srch_dest) > 1:\n",
    "            for dest in srch_dest:   \n",
    "                props.append(prop)\n",
    "                means.append(mean)\n",
    "                srch_destination.append(dest)\n",
    "        else:\n",
    "            props.append(prop)\n",
    "            means.append(mean)\n",
    "            srch_destination.append(srch_dest[0])\n",
    "    if len(props)%deci == 0:\n",
    "        i += 1\n",
    "        print(i*10, '%', end='\\t')\n",
    "    \n",
    "database = pd.DataFrame()\n",
    "database['prop_id'] = np.asarray(props)\n",
    "database['srch_destination_id'] = np.asarray(srch_destination)\n",
    "database['mean_srch_query_affinity_score'] = np.asarray(means)\n",
    "database.to_csv('hotel_affinity_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tImpute mean of the people from the same country:\n",
      "MSE: 13.882222527986682\n",
      "SD: 31.365682804256604\n",
      "\n",
      "\tImpute mean of everyone:\n",
      "MSE: 16.066876944759166\n",
      "SD: 34.302345344899905\n",
      "\n",
      "0.0 % of the instances had no other searches from the same country with a history.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "dfstar = df[df['srch_query_affinity_score'].notnull()][['prop_id', 'srch_destination_id', 'srch_query_affinity_score']].drop_duplicates()\n",
    "pred = list()\n",
    "h = 0\n",
    "for entry in dfstar.values:\n",
    "    prop_id = entry[0]\n",
    "    srch_dest = entry[1]\n",
    "    same_loc_df = database[(database['prop_id'] == prop_id)]\n",
    "    if len(same_loc_df) > 0:\n",
    "        pred.append(same_loc_df['mean_srch_query_affinity_score'].mean())\n",
    "    else: # if the hotel doesnt have a affinity score anywhere\n",
    "        same_loc_df = database[database['srch_destination_id'] == srch_dest]\n",
    "        if len(same_loc_df) > 0:\n",
    "            pred.append(same_loc_df['mean_srch_query_affinity_score'].mean())\n",
    "        else:\n",
    "            h += 1\n",
    "            pred.append(database['mean_srch_query_affinity_score'].mean())\n",
    "            \n",
    "pred = np.asarray(pred)\n",
    "\n",
    "print('\\tImpute mean of the people from the same hotel:')\n",
    "print('MSE:', math.sqrt(((dfstar['srch_query_affinity_score'] - pred)**2).mean()))\n",
    "print('SD:', math.sqrt(((dfstar['srch_query_affinity_score'] - pred)**2).std()))\n",
    "print()\n",
    "print('\\tImpute mean of everyone:')\n",
    "print('MSE:', math.sqrt(((dfstar['srch_query_affinity_score'] - dfstar['srch_query_affinity_score'].mean())**2).mean()))\n",
    "print('SD:', math.sqrt(((dfstar['srch_query_affinity_score'] - dfstar['srch_query_affinity_score'].mean())**2).std()))\n",
    "print()\n",
    "print(f'{round(h/len(dfstar),2)*100} % of the instances had no other searches from the same country with a history.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
