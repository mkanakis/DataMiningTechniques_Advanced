{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPUTING VALUES FOR THE NAN'S\n",
    "\n",
    "\n",
    "# visitor_hist_starrating:  94.92 % & visitor_hist_adr_usd: 94.9 %\n",
    "Imputing a single value didnt produce nice results. So I first imputed the mean of people from the same country going to the same destination. The remaining missing values were replaced by the mean of people from the same country going to the same country. After that I imputed the mean of the people from the same country. If there were any missing values left it was filled by the mean of everyone.\n",
    "\n",
    "Note. I did a lot more testing but didnt add it to the notebook to make sure it is clear what i did. This procedure produced the best results.\n",
    "\n",
    "\n",
    "# prop_review_score:  0.15 %\n",
    "Imputing a single value worked for prop_review_score. The correlation between prop_review_score and click_bool is highest when we impute 0 for the missing values. \n",
    "\n",
    "\n",
    "# prop_location_score2:  21.99 %\n",
    "It seems that the location_score2 is based on the search destination and the hotel location. It is probable that the further away the hotel is from the original search destination the lower the location_score2 is. Imputing a single value worked for prop_location_score2. The correlation between prop_location_score2 and click_bool is highest when we impute 0 for the missing values. \n",
    "\n",
    "\n",
    "# srch_query_affinity_score:  93.6 %\n",
    "Imputing a single value didnt produce nice results. So I first imputed the mean of the property in other searches. The remaining missing values were replaced by the mean of people with the same site_id going to the same destination. After that I imputed the mean of the same site_id going to the same country. If there were any missing values left it was filled by the mean of everyone.\n",
    "\n",
    "\n",
    "# orig_destination_distance:  32.43 %\n",
    "Either a search has the distance for every result or for none. Imputing the max distance for all missing values gives the best result. This would increase the correlation of this attribute with the click_bool from r = .0023 to r = .0057. Although this correlation is still really weak, it is a simple, fast and effective solution to improve the quality of this attribute.\n",
    "\n",
    "\n",
    "# Gross bookings USD: 97.21 %\n",
    "An attribute that only occurs when a hotel is booked. Doesnt have much relevance to predicting clicks for now.\n",
    "\n",
    "\n",
    "# Competitors: +- 80%\n",
    "The ratings, invs, and perc difference columns were aggregrated. So from 24 columns reduced to 3. The ratings and invs columns have around 30% missing values, while the perc difference column has about 70% missing values. After some experimentation the following was imputed: for invs and perc difference the minimum was imputed and for ratings the mean was imputed. These values gave the most acceptable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4958347, 54)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('training_set_VU_DM_2014.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tPercentage of missing values:\n",
      "visitor_hist_starrating:  94.92 %\n",
      "visitor_hist_adr_usd:  94.9 %\n",
      "prop_review_score:  0.15 %\n",
      "prop_location_score2:  21.99 %\n",
      "srch_query_affinity_score:  93.6 %\n",
      "orig_destination_distance:  32.43 %\n",
      "comp1_rate:  97.58 %\n",
      "comp1_inv:  97.39 %\n",
      "comp1_rate_percent_diff:  98.1 %\n",
      "comp2_rate:  59.17 %\n",
      "comp2_inv:  57.04 %\n",
      "comp2_rate_percent_diff:  88.78 %\n",
      "comp3_rate:  69.06 %\n",
      "comp3_inv:  66.7 %\n",
      "comp3_rate_percent_diff:  90.46 %\n",
      "comp4_rate:  93.8 %\n",
      "comp4_inv:  93.07 %\n",
      "comp4_rate_percent_diff:  97.36 %\n",
      "comp5_rate:  55.18 %\n",
      "comp5_inv:  52.4 %\n",
      "comp5_rate_percent_diff:  83.04 %\n",
      "comp6_rate:  95.16 %\n",
      "comp6_inv:  94.74 %\n",
      "comp6_rate_percent_diff:  98.06 %\n",
      "comp7_rate:  93.64 %\n",
      "comp7_inv:  92.81 %\n",
      "comp7_rate_percent_diff:  97.21 %\n",
      "comp8_rate:  61.34 %\n",
      "comp8_inv:  59.92 %\n",
      "comp8_rate_percent_diff:  87.6 %\n",
      "gross_bookings_usd:  97.21 %\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\tPercentage of missing values:')\n",
    "for column in df.columns:\n",
    "    percentage = round((len(df[df[column].isnull()])/len(df))*100,2)\n",
    "    if percentage > 0:\n",
    "        print(column + ': ', percentage, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mick\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.0005694839393124071\n",
      "median 0.000626779442498795\n",
      "zero -0.0004418415627816627\n",
      "firstq 0.00017204834390984516\n",
      "thirdq 0.0008006384089318516\n",
      "max 0.0007517801820802357\n",
      "min -0.00034362416781758665\n",
      "visitor_hist_starrating had an original correlation of 0.00254 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "mean 0.0008671475997370066\n",
      "median 0.000736350692485108\n",
      "zero 1.3140062061918199e-05\n",
      "firstq 0.0004715742465620082\n",
      "thirdq 0.0009906589213724986\n",
      "max 0.0005793425650268978\n",
      "min 1.3140062061918199e-05\n",
      "visitor_hist_adr_usd had an original correlation of 0.00386 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "mean 0.023410036946974796\n",
      "median 0.023394072813756547\n",
      "zero 0.023444060320061386\n",
      "firstq 0.023427803146072346\n",
      "thirdq 0.0233524831940233\n",
      "max 0.023303091176428058\n",
      "min 0.023444060320061386\n",
      "prop_review_score had an original correlation of r = 0.02342 with the click_bool. \n",
      "Best option: impute zero with r = 0.02344\n",
      "\n",
      "mean 0.06901988487992158\n",
      "median 0.07717329274108041\n",
      "zero 0.0830891483102491\n",
      "firstq 0.08180129772425819\n",
      "thirdq 0.06068962426309724\n",
      "max -0.02336453198980535\n",
      "min 0.0830891483102491\n",
      "prop_location_score2 had an original correlation of r = 0.07381 with the click_bool. \n",
      "Best option: impute zero with r = 0.08309\n",
      "\n",
      "mean 0.010516152579532935\n",
      "median 0.010380805872749749\n",
      "zero 0.006347827517613641\n",
      "firstq 0.009525012745072095\n",
      "thirdq 0.00907690509024209\n",
      "max 0.006771862127255129\n",
      "min -1.8980375418811273e-06\n",
      "srch_query_affinity_score had an original correlation of 0.04176 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "mean 0.0018647214595741294\n",
      "median 0.0004550771013060924\n",
      "zero -0.00011236866601645116\n",
      "firstq 8.890656601434174e-05\n",
      "thirdq 0.002165454718433614\n",
      "max 0.005732105526460014\n",
      "min -0.00011235444757496976\n",
      "orig_destination_distance had an original correlation of r = 0.00229 with the click_bool. \n",
      "Best option: impute max with r = 0.00573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First check the simplest solutions of imputing 1 value for all missing values in a column\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "for column in ['visitor_hist_starrating','visitor_hist_adr_usd', 'prop_review_score',\n",
    "'prop_location_score2','srch_query_affinity_score','orig_destination_distance']:\n",
    "    \n",
    "    result = []\n",
    "    df2 = df[[column, 'click_bool']]\n",
    "\n",
    "    r1, p = pearsonr(df2[df2[column].notnull()][column], df2[df2[column].notnull()]['click_bool'])\n",
    "    result.append((r1, 'old'))\n",
    "    for option in ['mean', 'median', 'zero', 'firstq', 'thirdq', 'max', 'min']:\n",
    "        df2 = df[[column, 'click_bool']]\n",
    "        if option == 'mean':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].mean())\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'median':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].median())\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'zero':\n",
    "            df2.loc[:,column] = df2[column].fillna(0)\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'firstq':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].quantile(q = .25))\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'thirdq':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].quantile(q = .75))\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'max':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].max())\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'min':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].min())\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        result.append((r, option))\n",
    "        print(option, r)\n",
    "    if r1 > 0:\n",
    "        best_corr, best_option = max(result)\n",
    "    elif r1 < 0:\n",
    "        best_corr, best_option = min(result)\n",
    "    if best_option != 'old':\n",
    "        print(f\"{column} had an original correlation of r = {round(r1, 5)} with the click_bool. \\nBest option: impute {best_option} with r = {round(best_corr, 5)}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{column} had an original correlation of {round(r1, 5)} with the click_bool. \\nThere was no better alternative.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visitor History rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptstar1 = pd.pivot_table(df, values='visitor_hist_starrating', index=['visitor_location_country_id', 'srch_destination_id'], aggfunc='mean').dropna().reset_index()\n",
    "new_df = pd.merge(df.drop('visitor_hist_starrating', 1), ptstar1, how='left', on=['visitor_location_country_id', 'srch_destination_id'])\n",
    "df.loc[:, 'visitor_hist_starrating'] = df['visitor_hist_starrating'].fillna(new_df['visitor_hist_starrating'])\n",
    "del ptstar1, new_df\n",
    "\n",
    "ptstar2 = pd.pivot_table(df, values='visitor_hist_starrating', index=['visitor_location_country_id', 'prop_country_id'], aggfunc='mean').dropna().reset_index()\n",
    "new_df = pd.merge(df.drop('visitor_hist_starrating', 1), ptstar2, how='left', on=['visitor_location_country_id', 'prop_country_id'])\n",
    "df.loc[:, 'visitor_hist_starrating'] = df['visitor_hist_starrating'].fillna(new_df['visitor_hist_starrating'])\n",
    "del ptstar2, new_df\n",
    "\n",
    "ptstar3 = pd.pivot_table(df, values='visitor_hist_starrating', index=['visitor_location_country_id'], aggfunc = 'mean').dropna().reset_index()\n",
    "new_df = pd.merge(df.drop('visitor_hist_starrating', 1), ptstar3, how='left', on=['visitor_location_country_id'])\n",
    "df.loc[:, 'visitor_hist_starrating'] = df['visitor_hist_starrating'].fillna(new_df['visitor_hist_starrating'])\n",
    "del ptstar3, new_df\n",
    "\n",
    "df.loc[:, 'visitor_hist_starrating'] = df['visitor_hist_starrating'].fillna(df['visitor_hist_starrating'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visitor history price usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ptprice1 = pd.pivot_table(df, values='visitor_hist_adr_usd', index=['visitor_location_country_id', 'srch_destination_id'], aggfunc='mean').dropna().reset_index()\n",
    "new_df = pd.merge(df.drop('visitor_hist_adr_usd', 1), ptprice1, how='left', on=['visitor_location_country_id', 'srch_destination_id'])\n",
    "df.loc[:, 'visitor_hist_adr_usd'] = df['visitor_hist_adr_usd'].fillna(new_df['visitor_hist_adr_usd'])\n",
    "del ptprice1, new_df\n",
    "\n",
    "ptprice2 = pd.pivot_table(df, values='visitor_hist_adr_usd', index=['visitor_location_country_id', 'prop_country_id'], aggfunc='mean').dropna().reset_index()\n",
    "new_df = pd.merge(df.drop('visitor_hist_adr_usd', 1), ptprice2, how='left', on=['visitor_location_country_id', 'prop_country_id'])\n",
    "df.loc[:, 'visitor_hist_adr_usd'] = df['visitor_hist_adr_usd'].fillna(new_df['visitor_hist_adr_usd'])\n",
    "del ptprice2, new_df\n",
    "\n",
    "ptprice3 = pd.pivot_table(df, values='visitor_hist_adr_usd', index=['visitor_location_country_id'], aggfunc = 'mean').dropna().reset_index()\n",
    "new_df = pd.merge(df.drop('visitor_hist_adr_usd', 1), ptprice3, how='left', on=['visitor_location_country_id'])\n",
    "df.loc[:, 'visitor_hist_adr_usd'] = df['visitor_hist_adr_usd'].fillna(new_df['visitor_hist_adr_usd'])\n",
    "del ptprice3, new_df\n",
    "\n",
    "df.loc[:, 'visitor_hist_adr_usd'] = df['visitor_hist_adr_usd'].fillna(df['visitor_hist_adr_usd'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# srch_query_affinity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptquery1 = pd.pivot_table(df, values='srch_query_affinity_score', index=['prop_id'], aggfunc='mean').dropna().reset_index()\n",
    "new_df = pd.merge(df.drop('srch_query_affinity_score', 1), ptquery1, how='left', on=['prop_id'])\n",
    "df.loc[:, 'srch_query_affinity_score'] = df['srch_query_affinity_score'].fillna(new_df['srch_query_affinity_score'])\n",
    "del ptquery1, new_df\n",
    "\n",
    "ptquery2 = pd.pivot_table(df, values='srch_query_affinity_score', index=['site_id', 'srch_destination_id'], aggfunc='mean').dropna().reset_index()\n",
    "new_df = pd.merge(df.drop('srch_query_affinity_score', 1), ptquery2, how='left', on=['site_id', 'srch_destination_id'])\n",
    "df.loc[:, 'srch_query_affinity_score'] = df['srch_query_affinity_score'].fillna(new_df['srch_query_affinity_score'])\n",
    "del ptquery2, new_df\n",
    "\n",
    "ptquery3 = pd.pivot_table(df, values='srch_query_affinity_score', index=['site_id', 'prop_country_id'], aggfunc = 'mean').dropna().reset_index()\n",
    "new_df = pd.merge(df.drop('srch_query_affinity_score', 1), ptquery3, how='left', on=['site_id', 'prop_country_id'])\n",
    "df.loc[:, 'srch_query_affinity_score'] = df['srch_query_affinity_score'].fillna(new_df['srch_query_affinity_score'])\n",
    "del ptquery3, new_df\n",
    "\n",
    "df.loc[:, 'srch_query_affinity_score'] = df['srch_query_affinity_score'].fillna(df['srch_query_affinity_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Competitor information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mick\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp1_rate had an original correlation of 0.00794 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp1_inv had an original correlation of -0.00726 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp1_rate_percent_diff had an original correlation of 0.00213 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp2_rate had an original correlation of 0.01695 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp2_inv had an original correlation of r = -0.00028 with the click_bool. \n",
      "Best option: impute min with r = -0.00441\n",
      "\n",
      "comp2_rate_percent_diff had an original correlation of 0.00139 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp3_rate had an original correlation of 0.01563 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp3_inv had an original correlation of -0.00672 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp3_rate_percent_diff had an original correlation of r = -0.0018 with the click_bool. \n",
      "Best option: impute max with r = -0.00452\n",
      "\n",
      "comp4_rate had an original correlation of 0.01817 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp4_inv had an original correlation of r = -0.00093 with the click_bool. \n",
      "Best option: impute max with r = -0.00371\n",
      "\n",
      "comp4_rate_percent_diff had an original correlation of 0.00195 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp5_rate had an original correlation of 0.02143 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp5_inv had an original correlation of -0.0031 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp5_rate_percent_diff had an original correlation of r = -0.00143 with the click_bool. \n",
      "Best option: impute max with r = -0.00245\n",
      "\n",
      "comp6_rate had an original correlation of 0.01318 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp6_inv had an original correlation of r = -0.00502 with the click_bool. \n",
      "Best option: impute max with r = -0.00505\n",
      "\n",
      "comp6_rate_percent_diff had an original correlation of 0.00648 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp7_rate had an original correlation of 0.01448 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp7_inv had an original correlation of -0.00691 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp7_rate_percent_diff had an original correlation of 0.00778 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp8_rate had an original correlation of 0.02366 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "comp8_inv had an original correlation of r = -0.00046 with the click_bool. \n",
      "Best option: impute min with r = -0.00713\n",
      "\n",
      "comp8_rate_percent_diff had an original correlation of -0.00164 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First check the simplest solutions of imputing 1 value for all missing values in a column\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "for column in ['comp1_rate', 'comp1_inv',\n",
    "       'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv',\n",
    "       'comp2_rate_percent_diff', 'comp3_rate', 'comp3_inv',\n",
    "       'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv',\n",
    "       'comp4_rate_percent_diff', 'comp5_rate', 'comp5_inv',\n",
    "       'comp5_rate_percent_diff', 'comp6_rate', 'comp6_inv',\n",
    "       'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv',\n",
    "       'comp7_rate_percent_diff', 'comp8_rate', 'comp8_inv',\n",
    "       'comp8_rate_percent_diff']:\n",
    "    \n",
    "    result = []\n",
    "    df2 = df[[column, 'click_bool']]\n",
    "\n",
    "    r1, p = pearsonr(df2[df2[column].notnull()][column], df2[df2[column].notnull()]['click_bool'])\n",
    "    result.append((r1, 'old'))\n",
    "    for option in ['mean', 'median', 'zero', 'firstq', 'thirdq', 'max', 'min']:\n",
    "        df2 = df[[column, 'click_bool']]\n",
    "        if option == 'mean':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].mean())\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'median':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].median())\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'zero':\n",
    "            df2.loc[:,column] = df2[column].fillna(0)\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'firstq':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].quantile(q = .25))\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'thirdq':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].quantile(q = .75))\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'max':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].max())\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'min':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].min())\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "\n",
    "        result.append((r, option))\n",
    "    if r1 > 0:\n",
    "        best_corr, best_option = max(result)\n",
    "    elif r1 < 0:\n",
    "        best_corr, best_option = min(result)\n",
    "    if best_option != 'old':\n",
    "        print(f\"{column} had an original correlation of r = {round(r1, 5)} with the click_bool. \\nBest option: impute {best_option} with r = {round(best_corr, 5)}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{column} had an original correlation of {round(r1, 5)} with the click_bool. \\nThere was no better alternative.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some comments\n",
    "As expected imputing the one value for all missing values doesnt seem to work well. For many there are no better alternatives, and for some there are. But for the ones with a better alternative the correlation with click_bool is still extremely low. Next i will try to combine the info of the competitors into less variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_bool</th>\n",
       "      <th>invmean</th>\n",
       "      <th>ratemean</th>\n",
       "      <th>diffsmean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>click_bool</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003433</td>\n",
       "      <td>0.023587</td>\n",
       "      <td>0.014690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invmean</th>\n",
       "      <td>-0.003433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.033479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratemean</th>\n",
       "      <td>0.023587</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diffsmean</th>\n",
       "      <td>0.014690</td>\n",
       "      <td>0.033479</td>\n",
       "      <td>0.111519</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            click_bool   invmean  ratemean  diffsmean\n",
       "click_bool    1.000000 -0.003433  0.023587   0.014690\n",
       "invmean      -0.003433  1.000000  0.000526   0.033479\n",
       "ratemean      0.023587  0.000526  1.000000   0.111519\n",
       "diffsmean     0.014690  0.033479  0.111519   1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The mean for the 3 different attributes are taken based on the competitors that dont have missing values\n",
    "\n",
    "NUMBER_INSTANCES = len(df)\n",
    "\n",
    "rates = [\"comp1_rate\", \"comp2_rate\", \"comp3_rate\", \"comp4_rate\",\n",
    "         \"comp5_rate\", \"comp6_rate\", \"comp7_rate\", \"comp8_rate\"]\n",
    "\n",
    "invs = ['comp1_inv', 'comp2_inv', 'comp3_inv', 'comp4_inv',\n",
    "       'comp5_inv', 'comp6_inv', 'comp7_inv', 'comp8_inv']\n",
    "\n",
    "\n",
    "diffs = ['comp1_rate_percent_diff', 'comp2_rate_percent_diff', 'comp3_rate_percent_diff',\n",
    "        'comp4_rate_percent_diff', 'comp5_rate_percent_diff', 'comp6_rate_percent_diff',\n",
    "        'comp7_rate_percent_diff', 'comp8_rate_percent_diff']\n",
    "\n",
    "\n",
    "dfrates = df[rates]\n",
    "dfinvs = df[invs]\n",
    "dfdiffs = df[diffs]\n",
    "\n",
    "ratemean = []\n",
    "invsmean = []\n",
    "diffsmean =[]\n",
    "j = 0\n",
    "for i in range(len(dfrates))[:NUMBER_INSTANCES]:\n",
    "    rates = []\n",
    "    for value in dfrates.values[i]:\n",
    "        if value in [-1, 0, 1]:\n",
    "            rates.append(value)\n",
    "    \n",
    "    if len(rates) == 0:\n",
    "        ratemean.append(np.nan)\n",
    "    else:\n",
    "        ratemean.append(sum(rates)/len(rates))\n",
    "        \n",
    "    invs = []\n",
    "    for value in dfinvs.values[i]:\n",
    "        if value in [-1, 0, 1]:\n",
    "            invs.append(value)\n",
    "    \n",
    "    if len(invs) == 0:\n",
    "        invsmean.append(np.nan)\n",
    "    else:\n",
    "        invsmean.append(sum(invs)/len(invs))\n",
    "        \n",
    "    diffs = []\n",
    "    for value in dfdiffs.values[i]:\n",
    "        if (value < 500):\n",
    "            diffs.append(value)\n",
    "    \n",
    "    if len(diffs) == 0:\n",
    "        diffsmean.append(np.nan)\n",
    "    else:\n",
    "        diffsmean.append(sum(diffs)/len(diffs))\n",
    "    \n",
    "    if (i != 0) and (i%(NUMBER_INSTANCES/100) == 0):\n",
    "        j += 1\n",
    "        print(j, '%', end = ' ')\n",
    "\n",
    "invsmean = np.asarray(invsmean)\n",
    "ratemean = np.asarray(ratemean)\n",
    "diffsmean = np.asarray(diffsmean)\n",
    "\n",
    "dfcompetitors = df[['click_bool']][:NUMBER_INSTANCES]\n",
    "dfcompetitors.loc[:, 'invmean'] = invsmean\n",
    "dfcompetitors.loc[:, 'ratemean'] = ratemean\n",
    "dfcompetitors.loc[:, 'diffsmean'] = diffsmean\n",
    "dfcompetitors.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tPercentage of missing values:\n",
      "invmean:  32.39 %\n",
      "ratemean:  34.62 %\n",
      "diffsmean:  68.17 %\n"
     ]
    }
   ],
   "source": [
    "print('\\n\\tPercentage of missing values:')\n",
    "for column in dfcompetitors.columns:\n",
    "    percentage = round((len(dfcompetitors[dfcompetitors[column].isnull()])/len(dfcompetitors))*100,2)\n",
    "    if percentage > 0:\n",
    "        print(column + ': ', percentage, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More comments\n",
    "So using the original 24 features resulted in very low correlations with the click_bool. The aggregrated features have a higher correlations with the click_bool, and they have less missing values (from around 80% to to 30% for inv and rates and 66% for percentage difference). Next ill try to see if imputing 1 value for all missing values is possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mick\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean -0.0028119046683387308\n",
      "median -0.0030685901840169483\n",
      "zero -0.0030685901840169483\n",
      "firstq -0.0030685901840169483\n",
      "thirdq -0.0030685901840169483\n",
      "max 0.0012642007549602935\n",
      "min -0.003343811441173417\n",
      "invmean had an original correlation of -0.00343 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "mean 0.018965622495426035\n",
      "median 0.018866750640488584\n",
      "zero 0.018866750640488584\n",
      "firstq 0.018866750640488584\n",
      "thirdq 0.018866750640488584\n",
      "max 0.01413901599955859\n",
      "min 0.008288520911911764\n",
      "ratemean had an original correlation of 0.02359 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n",
      "mean 0.00840734215356335\n",
      "median 0.009178891821516679\n",
      "zero 0.00946734385087474\n",
      "firstq 0.009506568459263183\n",
      "thirdq 0.007899222781885476\n",
      "max -0.004113221370566694\n",
      "min 0.009523835130745723\n",
      "diffsmean had an original correlation of 0.01469 with the click_bool. \n",
      "There was no better alternative.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First check the simplest solutions of imputing 1 value for all missing values in a column\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "for column in ['invmean', 'ratemean', 'diffsmean']:\n",
    "    \n",
    "    result = []\n",
    "    df2 = dfcompetitors[[column, 'click_bool']]\n",
    "\n",
    "    r1, p = pearsonr(df2[df2[column].notnull()][column], df2[df2[column].notnull()]['click_bool'])\n",
    "    result.append((r1, 'old'))\n",
    "    \n",
    "    for option in ['mean', 'median', 'zero', 'firstq', 'thirdq', 'max', 'min']:\n",
    "        df2 = dfcompetitors[[column, 'click_bool']]\n",
    "        if option == 'mean':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].mean())\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'median':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].median())\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'zero':\n",
    "            df2.loc[:,column] = df2[column].fillna(0)\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'firstq':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].quantile(q = .25))\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'thirdq':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].quantile(q = .75))\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'max':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].max())\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        if option == 'min':\n",
    "            df2.loc[:,column] = df2[column].fillna(df2[column].min())\n",
    "            r, p = pearsonr(df2[column], df2['click_bool'])\n",
    "        print(option, r)\n",
    "        result.append((r, option))\n",
    "    if r1 > 0:\n",
    "        best_corr, best_option = max(result)\n",
    "    elif r1 < 0:\n",
    "        best_corr, best_option = min(result)\n",
    "    if best_option != 'old':\n",
    "        print(f\"{column} had an original correlation of r = {round(r1, 5)} with the click_bool. \\nBest option: impute {best_option} with r = {round(best_corr, 5)}\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"{column} had an original correlation of {round(r1, 5)} with the click_bool. \\nThere was no better alternative.\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion and further steps\n",
    "For the invmean it would be usefull to impute the minimum for all missing values since the reduction in the correlation with click_bool is 0.0001 which is almost nothing. \n",
    "\n",
    "For the ratemean we can decide to impute the mean, which would give a reduction of .004 with click_bool. This is still not a big difference but we have to be carefull when deciding this.\n",
    "\n",
    "The min of diffsmean can be imputed since it gives a reduction of .005 with click_bool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mick\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "C:\\Users\\Mick\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click_bool</th>\n",
       "      <th>ratemean</th>\n",
       "      <th>invmean</th>\n",
       "      <th>diffsmean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>click_bool</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018966</td>\n",
       "      <td>-0.003344</td>\n",
       "      <td>0.009524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratemean</th>\n",
       "      <td>0.018966</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.115153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>invmean</th>\n",
       "      <td>-0.003344</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.241298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diffsmean</th>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.115153</td>\n",
       "      <td>0.241298</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            click_bool  ratemean   invmean  diffsmean\n",
       "click_bool    1.000000  0.018966 -0.003344   0.009524\n",
       "ratemean      0.018966  1.000000  0.000112   0.115153\n",
       "invmean      -0.003344  0.000112  1.000000   0.241298\n",
       "diffsmean     0.009524  0.115153  0.241298   1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What happens when we concatenate the two dataframes and fill in the ratemean and diffsmean and compute rate*diff\n",
    "dfcompetitors2 = df[['click_bool']]\n",
    "dfcompetitors2.loc[:, 'ratemean'] = dfcompetitors['ratemean'].fillna(dfcompetitors['ratemean'].mean())\n",
    "dfcompetitors2.loc[:, 'invmean'] = dfcompetitors['invmean'].fillna(dfcompetitors['ratemean'].min())\n",
    "dfcompetitors2.loc[:, 'diffsmean'] = dfcompetitors['diffsmean'].fillna(dfcompetitors['diffsmean'].min())\n",
    "dfcompetitors2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfcompetitors2.drop('click_bool', 1).to_csv('Dataset_Competitors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets create a new df with no NAN-values\n",
    "Except for the visitor history rating/price :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = df[['srch_id', 'date_time', 'site_id', 'visitor_location_country_id',\n",
    "       'visitor_hist_starrating', 'visitor_hist_adr_usd', 'prop_country_id',\n",
    "       'prop_id', 'prop_starrating', 'prop_review_score', 'prop_brand_bool',\n",
    "       'prop_location_score1', 'prop_location_score2',\n",
    "       'prop_log_historical_price', 'position', 'price_usd', 'promotion_flag',\n",
    "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
    "       'srch_adults_count', 'srch_children_count', 'srch_room_count',\n",
    "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
    "       'orig_destination_distance', 'random_bool', 'click_bool', \n",
    "       'gross_bookings_usd', 'booking_bool']]\n",
    "\n",
    "finaldf.loc[:, 'prop_review_score'] = finaldf['prop_review_score'].fillna(0)\n",
    "print('prop_review_score = done')\n",
    "finaldf.loc[:, 'prop_location_score2'] = finaldf['prop_location_score2'].fillna(0)\n",
    "print('prop_location_score2 = done') \n",
    "finaldf.loc[:, 'orig_destination_distance'] = finaldf['orig_destination_distance'].fillna(finaldf['orig_destination_distance'].max())\n",
    "print('orig_desination_distance = done')\n",
    "dfcompetitors2 = dfcompetitors2.drop('click_bool', 1)\n",
    "finaldf = pd.concat([finaldf, dfcompetitors2], axis=1, join_axes=[finaldf.index])\n",
    "print('competitors info = done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finaldf.to_csv('Dataset_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
